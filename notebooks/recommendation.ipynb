{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the cleaned recommendation dataset\n",
    "recommendation_data = pd.read_csv(\"C:/project/fashion-recommender-system/data/processed/fashion-mnist_train_cleaned.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X_recommend = recommendation_data.iloc[:, 1:].values  # Pixel values\n",
    "y_recommend = recommendation_data.iloc[:, 0].values  # Labels (category or class)\n",
    "\n",
    "# Normalize pixel values (0-255 to 0-1)\n",
    "X_recommend = X_recommend / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is loaded, and features (pixel values) and labels (classes) are separated. Normalization is performed for better computational efficiency.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data (mean = 0, variance = 1)\n",
    "scaler = StandardScaler()\n",
    "X_recommend_standardized = scaler.fit_transform(X_recommend)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization scales the features to have a mean of 0 and a variance of 1. This is particularly important for algorithms like PCA and cosine similarity, as it ensures that the distance calculations are not biased by the scale of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dimensionality Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce dimensions to 50 components\n",
    "pca = PCA(n_components=10)\n",
    "X_recommend_pca = pca.fit_transform(X_recommend_standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA reduces the dimensionality of the feature set to 50 components, helping maintain data variance while decreasing computation time and memory usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dimensionality Reduction via TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Apply Truncated SVD to reduce dimensions to 50 components\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "X_recommend_svd = svd.fit_transform(X_recommend_standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated SVD is effective for sparse datasets, reducing dimensionality while preserving essential features, which allows for faster computations and lower memory requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Updated Batch Cosine Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def batch_cosine_similarity(X, batch_size=100):\n",
    "    n_samples = X.shape[0]\n",
    "    similarity_matrix = csr_matrix((n_samples, n_samples))  # Create a sparse matrix\n",
    "\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        end = min(i + batch_size, n_samples)\n",
    "        # Compute cosine similarity for the current batch\n",
    "        batch_similarity = cosine_similarity(X[i:end], X)\n",
    "        similarity_matrix[i:end, :] = batch_similarity\n",
    "\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The updated batch_cosine_similarity function computes cosine similarity in smaller batches to manage memory usage effectively.\n",
    "2. It returns a sparse matrix, saving memory while still providing necessary similarity scores for large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate Similarity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity matrix for PCA reduced data\n",
    "similarity_matrix_batch_pca = batch_cosine_similarity(X_recommend_pca, batch_size=100)  # Adjust batch size\n",
    "\n",
    "# Calculate similarity matrix for SVD reduced data\n",
    "similarity_matrix_batch_svd = batch_cosine_similarity(X_recommend_svd, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity matrices for both PCA and SVD reduced datasets are recomputed using batch processing, ensuring efficient memory utilization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(item_index, similarity_matrix, N=5):\n",
    "    similarity_scores = similarity_matrix[item_index].toarray().flatten()  # Convert sparse to dense for indexing\n",
    "    top_N_indices = similarity_scores.argsort()[::-1][1:N + 1]  # Exclude the item itself\n",
    "    return top_N_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified get_recommendations function retrieves the top N similar items based on similarity scores, ensuring that the input item is excluded from its own recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Recommendation Using Batch PCA Similarity Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_items_batch_pca = get_recommendations(0, similarity_matrix_batch_pca, N=5)\n",
    "print(\"Recommended items (Batch PCA):\", recommended_items_batch_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This step demonstrates how to use the recommendation function to find similar items for the first item in the dataset.\n",
    "2. The output will display the indices of the top recommended items based on PCA similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save PCA and SVD models\n",
    "joblib.dump(pca, 'pca_model.pkl')\n",
    "joblib.dump(svd, 'svd_model.pkl')\n",
    "\n",
    "# Save the scaler model\n",
    "joblib.dump(scaler, 'scaler_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained PCA, SVD, and standardization models are saved using joblib, enabling quick loading in future sessions and preventing the need for retraining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
